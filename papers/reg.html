<title>Adaptive</title>
<p>
<b> <h3> <center>Adaptive Markov Chain Monte Carlo through Regeneration.
 </center> </h3> </b>
 
<center>
Wally R. Gilks,
  Gareth O. Roberts,   
    Sujit K. Sahu 
          </center>       


<h2>
This paper has appeared as
</h2>

<li>
Gilks, W. R., Roberts, G. O. and Sahu, S. K. (1998) Adaptive Markov Chain
Monte Carlo through Regeneration. <i>Journal of the American Statistical
Association, </i><b>93,
</b>1045--1054.</li>

<b>
<h4>          
 SUMMARY 
 </h4> </b>
</center>
<p>

Markov chain Monte Carlo (MCMC) is used for evaluating expectations of functions of interest under a target distribution 
$\pi$. This is done by calculating averages over the sample path of a Markov chain having $\pi$ 
as its stationary distribution. For computational efficiency, the 
Markov chain should be rapidly mixing. This can sometimes be achieved
 only by careful design of the transition kernel of the chain, on the basis 
 of a detailed  preliminary exploratory analysis of $\pi$. An alternative 
 approach might be to allow  the transition kernel to adapt whenever new features 
 of $\pi$ are encountered during the MCMC run. However, if such adaptation occurs 
 infinitely often,  the stationary distribution of the chain may be disturbed. 
 We describe a framework, based on the concept of Markov chain regeneration, which 
 allows adaptation to occur infinitely often, but which does not disturb the 
 stationary distribution of the chain or the consistency of sample-path averages.

<p>
Key Words: Adaptive method; 
Bayesian inference; Gibbs sampling; Markov chain Monte Carlo; 
Metropolis--Hastings algorithm; Mixing rate; Regeneration; Splitting.



<hr>
<a href="../index.html" > Back to </a> my page. 
<address>
S.K.Sahu@maths.soton.ac.uk 
</address>
<p>


